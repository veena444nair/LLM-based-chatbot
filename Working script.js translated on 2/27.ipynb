{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgHOTxWix616H8lfXQooFY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/veena444nair/LLM-based-chatbot/blob/master/Working%20script.js%20translated%20on%202/27.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uEASrZgRQVd"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI, Request\n",
        "import uuid\n",
        "import requests\n",
        "import json\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "api_key = \"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\"\n",
        "url = \"https://api.openai.com/v1/chat/completions\"\n",
        "headers = {\n",
        "    'Content-Type': 'application/json',\n",
        "    'Authorization': f'Bearer {api_key}'\n",
        "}\n",
        "\n",
        "file_path = \"conversation_history.txt\"\n",
        "\n",
        "# Read the conversation history from the file\n",
        "try:\n",
        "    with open(file_path, \"r\") as file:\n",
        "        conversation_history = file.read()\n",
        "except FileNotFoundError:\n",
        "    # If the file does not exist, initialize conversation_history with a default system message\n",
        "    conversation_history = [{'role': 'system', 'content': \"You are a bot just starting a conversation.\"}]\n",
        "\n",
        "\n",
        "@app.get(\"/\")\n",
        "\n",
        "def get_chuck_norris_joke(query_param: str):\n",
        "\n",
        "\t# Get the last message from the conversation history\n",
        "\tlast_message = conversation_history\n",
        "\n",
        "\t# Append the new user message in the specified format\n",
        "\tconversation_history.append({'role': 'user', 'content': query_param})\n",
        "\tpayload = {\n",
        "     \t   'messages': [\n",
        "      \t      {\n",
        "      \t          'role': 'system',\n",
        "      \t          'content': last_message\n",
        "      \t      },\n",
        "      \t      {\n",
        "       \t         'role': 'user',\n",
        "       \t         'content': query_param\n",
        "       \t      }\n",
        "           ],\n",
        "        'max_tokens': 500,\n",
        "        'model': 'gpt-3.5-turbo'\n",
        "\t}\n",
        "\ttry:\n",
        "    response = requests.post(url, json=payload, headers=headers)\n",
        "        \tresponse.raise_for_status()\n",
        "\n",
        "        \tjoke = response.json()\n",
        "\n",
        "        \t# Append the new user message and bot response to the conversation history\n",
        "        \tconversation_history.append({'role': 'user', 'content': query_param})\n",
        "        \tconversation_history.append({'role': 'assistant', 'content': joke})\n",
        "\n",
        " \t\t# Write the entire conversation history to the text file\n",
        "          with open(\"conversation_history.txt\", \"a\") as file:\n",
        "            for message in conversation_history:\n",
        "\t\t\tfile.write(f\"{message['role']}: {message['content']}\\n\")\n",
        "\t\t\treturn {\"joke\": joke}\n",
        "\n",
        "\texcept Exception as e:\n",
        "\n",
        "        \tprint(\"Error:\", e)\n",
        "        \treturn {\"joke\": \"An error occurred while fetching the Chuck Norris joke.\"}\n",
        "\telse:\n",
        "        return {\"joke\": \"No query parameter provided.\"}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MESSING AROUND WITH THIS BELOW\n",
        "!!!!\n",
        "!!!\n",
        "!!!!!\n"
      ],
      "metadata": {
        "id": "-vshBt8aRXPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install FastAPI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV86aERWeet0",
        "outputId": "45a19311-af13-41ca-d332-a3ba453028af"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting FastAPI\n",
            "  Downloading fastapi-0.100.0-py3-none-any.whl (65 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/65.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from FastAPI) (1.10.12)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from FastAPI)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from FastAPI) (4.7.1)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.28.0,>=0.27.0->FastAPI) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->FastAPI) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->FastAPI) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->FastAPI) (1.1.2)\n",
            "Installing collected packages: starlette, FastAPI\n",
            "Successfully installed FastAPI-0.100.0 starlette-0.27.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "   conversation_history+=\"({'role': 'user', 'content': \"f{query_param}\"})\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "wx8fGQKCebi3",
        "outputId": "7456542b-c318-4da3-a9b5-d728138603a3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-8f930b8ab1fb>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    conversation_history+=\"({'role': 'user', 'content': \"f{query_param}\"})\"\u001b[0m\n\u001b[0m                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STARTING OVER. TIRED OF DEBUGGING."
      ],
      "metadata": {
        "id": "yKjFJtEKsaJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehAC7CCXsgtH",
        "outputId": "e1bd60a2-5324-468a-8a29-a404ad595541"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "class Chatbot:\n",
        "    def __init__(self):\n",
        "        self.api_key = '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'\n",
        "        self.url = 'https://api.openai.com/v1/chat/completions'\n",
        "        self.headers = {\n",
        "            'Content-Type': 'application/json',\n",
        "            'Authorization': f'Bearer {self.api_key}'\n",
        "        }\n",
        "        self.prompt_url = 'https://assets.codepen.io/10352804/Prompt.txt'\n",
        "        self.conversation_history = self.fetch_prompt()\n",
        "\n",
        "    def fetch_prompt(self):\n",
        "        response = requests.get(self.prompt_url)\n",
        "        if response.status_code == 200:\n",
        "            return response.text\n",
        "        else:\n",
        "            print('Failed to fetch prompt')\n",
        "            return ''\n",
        "\n",
        "    def summarize_history(self, long_history):\n",
        "        conversation = {\n",
        "            'messages': [\n",
        "                {\n",
        "                    'role': 'system',\n",
        "                    'content': \"Summarize this text and shorten it's length to under 4096 tokens. But retain the important context.\"\n",
        "                },\n",
        "                {\n",
        "                    'role': 'user',\n",
        "                    'content': long_history\n",
        "                }\n",
        "            ],\n",
        "            'max_tokens': 500,\n",
        "            'model': 'gpt-3.5-turbo'\n",
        "        }\n",
        "        response = requests.post(self.url, json=conversation, headers=self.headers)\n",
        "        if response.status_code == 200:\n",
        "            summary = response.json()['choices'][0]['message']['content']\n",
        "            return summary\n",
        "        else:\n",
        "            print(f\"Error: {response.json()}\")\n",
        "            return \"An error occurred while summarizing the conversation history.\"\n",
        "\n",
        "    def get_chatbot_response(self, user_input):\n",
        "        payload = {\n",
        "            'messages': [\n",
        "                {\n",
        "                    'role': 'system',\n",
        "                    'content': self.conversation_history\n",
        "                },\n",
        "                {\n",
        "                    'role': 'user',\n",
        "                    'content': user_input\n",
        "                }\n",
        "            ],\n",
        "            'max_tokens': 500,\n",
        "            'model': 'gpt-3.5-turbo'\n",
        "        }\n",
        "        response = requests.post(self.url, json=payload, headers=self.headers)\n",
        "        if response.status_code == 200:\n",
        "            joke = response.json()['choices'][0]['message']['content']\n",
        "            return joke\n",
        "        else:\n",
        "            print(f\"Error: {response.json()}\")\n",
        "            return \"An error occurred while fetching the Chuck Norris joke.\"\n",
        "\n",
        "    def start_chat(self):\n",
        "        while True:\n",
        "            user_input = input('User: ').strip().lower()\n",
        "            chatbot_response = self.get_chatbot_response(user_input)\n",
        "            print(f'Chatbot: {chatbot_response}')\n",
        "            self.conversation_history += f'User: {user_input}\\nChatbot: {chatbot_response}\\n\\n'\n",
        "            self.conversation_history = self.summarize_history(self.conversation_history)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    chatbot = Chatbot()\n",
        "    chatbot.start_chat()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "id": "xIF4AtXcsei_",
        "outputId": "99d1f9dd-def9-4b91-f907-b46ba8d4a1e6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: pizza please\n",
            "Chatbot: Great! We have two pizza restaurants available for you to choose from. We have Natasha Pizza and Joy Pizzas. Which one would you prefer?\n",
            "User: vegan pizza\n",
            "Chatbot: Great choice! Here are the options for vegan pizza available at Natasha Pizza:\n",
            "\n",
            "1. Vegan pizza - $12.95\n",
            "2. Vegan pizza - $10.00\n",
            "3. Vegan pizza - $7.00\n",
            "\n",
            "Please let me know which option you'd like or if you have any other questions.\n",
            "User: what are the toppings?\n",
            "Chatbot: The toppings option 2 include pepperoni, onions, and mushrooms.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-9cde99be78b0>\u001b[0m in \u001b[0;36m<cell line: 77>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mchatbot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatbot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mchatbot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_chat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-9cde99be78b0>\u001b[0m in \u001b[0;36mstart_chat\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_chat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'User: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0mchatbot_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_chatbot_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Chatbot: {chatbot_response}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}